// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Prompt {
  id          String   @id @default(uuid())
  name        String   @unique
  description String?
  owner       String?
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  versions    PromptVersion[]
  environments PromptEnvBinding[]
}

model PromptVersion {
  id        String   @id @default(uuid())
  version   String   // e.g., "1.0.0", "v1"
  template  String   // The actual prompt text/template
  metadata  Json?    // Extra config (model, temperature, etc.)
  createdAt DateTime @default(now())
  
  promptId  String
  prompt    Prompt   @relation(fields: [promptId], references: [id])

  bindings  PromptEnvBinding[]

  @@unique([promptId, version])
}

model PromptEnvBinding {
  id        String   @id @default(uuid())
  env       String   // "prod", "dev", "test"
  
  promptId  String
  prompt    Prompt   @relation(fields: [promptId], references: [id])
  
  versionId String
  version   PromptVersion @relation(fields: [versionId], references: [id])

  updatedAt DateTime @updatedAt

  @@unique([promptId, env])
}

model RequestLog {
  id          String   @id @default(uuid())
  requestId   String   @unique
  timestamp   DateTime @default(now())
  
  // Context
  env         String
  provider    String
  model       String
  
  // Attribution
  promptId    String?
  promptVersion String?
  
  // Metrics
  latencyMs   Int
  tokensIn    Int
  tokensOut   Int
  costUsd     Float
  
  // Status
  status      String   // "success", "error"
  errorCode   String?
  errorMessage String?
  
  // Metadata (JSONB)
  metadata    Json?    // Client metadata, user_id, etc.

  @@index([env, timestamp])
  @@index([promptId])
  @@index([requestId])
}

// Evaluation & Regression Testing
model Dataset {
  id          String   @id @default(uuid())
  name        String   @unique
  description String?
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  
  testCases   TestCase[]
  runs        EvaluationRun[]
}

model TestCase {
  id          String   @id @default(uuid())
  datasetId   String
  dataset     Dataset  @relation(fields: [datasetId], references: [id])
  
  input       Json     // Variables to fill the prompt template
  expectedOutput String? // Optional "Golden" output
  metadata    Json?    // e.g. tags, difficulty
  
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  
  results     EvaluationResult[]
}

model EvaluationRun {
  id          String   @id @default(uuid())
  status      String   // "pending", "running", "completed", "failed"
  
  datasetId   String
  dataset     Dataset  @relation(fields: [datasetId], references: [id])
  
  // What are we evaluating?
  promptId    String
  promptVersionId String? // Optional, if specific version
  
  // Configuration override (e.g. testing a new model)
  config      Json?    // { provider: "openai", model: "gpt-4" }
  
  createdAt   DateTime @default(now())
  completedAt DateTime?
  
  score       Float?   // Aggregate score
  summary     Json?    // Detailed stats
  
  results     EvaluationResult[]
}

model EvaluationResult {
  id          String   @id @default(uuid())
  runId       String
  run         EvaluationRun @relation(fields: [runId], references: [id])
  
  testCaseId  String
  testCase    TestCase @relation(fields: [testCaseId], references: [id])
  
  output      String   // Actual LLM output
  score       Float    // 0.0 to 1.0
  reasoning   String?  // Why did it get this score?
  
  metrics     Json?    // Breakdown of metrics (faithfulness, relevancy, etc.)
  
  createdAt   DateTime @default(now())
}
